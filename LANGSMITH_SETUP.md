# LangSmith Integration Guide

## ðŸŽ¯ What is LangSmith?

LangSmith is LangChain's official monitoring and debugging platform. It helps you:
- **Track all LLM calls** - See every query, response, and token usage
- **Debug chains** - Visualize your RAG pipeline step-by-step
- **Monitor performance** - Response times, costs, errors
- **Evaluate quality** - Test different prompts and configurations
- **Analyze user queries** - Understand what users are asking

## ðŸš€ Setup Instructions

### **Step 1: Create LangSmith Account**

1. Go to: https://smith.langchain.com/
2. Sign up (free tier available)
3. Create a new organization
4. Create a project called "PadhAI-RAG"

### **Step 2: Get Your API Key**

1. Click on your profile (top right)
2. Go to **Settings** â†’ **API Keys**
3. Click **Create API Key**
4. Copy the key (starts with `lsv2_...`)

### **Step 3: Add to .env File**

Add these lines to your `.env` file:

```env
# LangSmith Tracking
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=lsv2_pt_your-api-key-here
LANGCHAIN_PROJECT=PadhAI-RAG
```

### **Step 4: Install LangSmith**

```bash
pip install langsmith
```

### **Step 5: Restart Backend**

```bash
# Stop current server (Ctrl+C)
python -m uvicorn server:app --reload --host 0.0.0.0 --port 8000
```

You should see:
```
âœ… LangSmith tracing enabled
```

## ðŸ“Š What You'll See in LangSmith

### **1. Every Chat Query**
- User question
- Retrieved chunks
- LLM prompt
- Final answer
- Token usage
- Response time

### **2. Chain Visualization**
```
User Query
    â†“
Embedding Generation (Gemini)
    â†“
FAISS Similarity Search
    â†“
Retrieve Top 10 Chunks
    â†“
Build Prompt with Context
    â†“
LLM Call (Groq DeepSeek)
    â†“
Final Answer
```

### **3. Performance Metrics**
- **Latency**: How long each step takes
- **Tokens**: Input/output token counts
- **Cost**: Estimated API costs
- **Success Rate**: % of successful queries

### **4. Debugging Info**
- Exact prompts sent to LLM
- Retrieved document chunks
- Intermediate steps
- Error traces

## ðŸŽ¨ LangSmith Dashboard Features

### **Traces Tab**
View all your RAG queries in real-time:
- Click any trace to see full details
- Filter by status, latency, user
- Search by query text

### **Datasets Tab**
Create test datasets:
```python
# Example test cases
test_queries = [
    "What is gradient descent?",
    "Explain backpropagation",
    "Compare CNN and RNN"
]
```

### **Evaluations Tab**
Run automated evaluations:
- Compare different prompts
- Test chunk sizes
- Measure accuracy improvements

### **Playground**
Test queries without code:
- Try different prompts
- Adjust parameters
- See results instantly

## ðŸ“ˆ Advanced Features

### **1. Custom Metadata**

Add custom tags to traces:

```python
from langsmith import traceable

@traceable(
    run_type="chain",
    name="RAG Query",
    metadata={"user_id": user_id, "folder": folder_name}
)
def chat_with_folder(folder_name, query):
    # Your existing code
    pass
```

### **2. Feedback Collection**

Track user feedback:

```python
from langsmith import Client

client = Client()

# After user rates answer
client.create_feedback(
    run_id=trace_id,
    key="user_rating",
    score=5,  # 1-5 stars
    comment="Very helpful!"
)
```

### **3. A/B Testing**

Compare different configurations:

```python
# Test different chunk sizes
configs = [
    {"chunk_size": 1000, "k": 6},
    {"chunk_size": 1500, "k": 10},
    {"chunk_size": 2000, "k": 8}
]

# LangSmith tracks which performs better
```

### **4. Cost Tracking**

Monitor API costs:
- Groq LLM calls
- Gemini embeddings
- Total per user/folder
- Daily/monthly trends

## ðŸ” Example: Viewing a Trace

When you ask: "What is gradient descent?"

**LangSmith shows:**

```
Trace: RAG Query
â”œâ”€ Embedding Generation
â”‚  â”œâ”€ Input: "What is gradient descent?"
â”‚  â”œâ”€ Model: models/embedding-001
â”‚  â”œâ”€ Output: [768-dim vector]
â”‚  â””â”€ Duration: 120ms
â”‚
â”œâ”€ Vector Search
â”‚  â”œâ”€ Query Vector: [768-dim]
â”‚  â”œâ”€ Top K: 10
â”‚  â”œâ”€ Retrieved Chunks: [chunk1, chunk2, ...]
â”‚  â””â”€ Duration: 45ms
â”‚
â”œâ”€ Prompt Construction
â”‚  â”œâ”€ Template: Custom RAG prompt
â”‚  â”œâ”€ Context: 10 chunks (15,234 chars)
â”‚  â”œâ”€ Question: "What is gradient descent?"
â”‚  â””â”€ Final Prompt: [full text]
â”‚
â””â”€ LLM Call
   â”œâ”€ Model: deepseek-r1-distill-llama-70b
   â”œâ”€ Input Tokens: 3,456
   â”œâ”€ Output Tokens: 234
   â”œâ”€ Answer: "Gradient descent is..."
   â”œâ”€ Duration: 2.3s
   â””â”€ Cost: $0.0023
```

## ðŸ“Š Metrics to Monitor

### **Quality Metrics**
- **Answer Relevance**: Does it answer the question?
- **Faithfulness**: Is it based on documents?
- **Context Precision**: Are retrieved chunks relevant?

### **Performance Metrics**
- **P95 Latency**: 95% of queries under X seconds
- **Error Rate**: % of failed queries
- **Token Usage**: Average tokens per query

### **Cost Metrics**
- **Cost per Query**: Average API cost
- **Daily Spend**: Total daily costs
- **Cost by User**: Who's using it most

## ðŸŽ¯ Best Practices

### **1. Tag Your Traces**
```python
metadata = {
    "user_id": user_id,
    "folder": folder_name,
    "environment": "production",
    "version": "1.0"
}
```

### **2. Create Test Datasets**
Build a set of test queries with expected answers:
```python
test_dataset = [
    {
        "query": "What is gradient descent?",
        "expected_keywords": ["optimization", "minimize", "derivative"]
    }
]
```

### **3. Set Up Alerts**
Configure alerts for:
- High error rates
- Slow responses (>5s)
- High costs (>$X/day)

### **4. Regular Reviews**
Weekly check:
- Most common queries
- Failed queries
- Slow queries
- Expensive queries

## ðŸ”§ Troubleshooting

### **Not Seeing Traces?**

1. Check `.env` has correct API key
2. Verify `LANGCHAIN_TRACING_V2=true`
3. Restart backend server
4. Check LangSmith project name matches

### **Traces Not Detailed Enough?**

Enable verbose logging:
```python
import langchain
langchain.verbose = True
```

### **Too Many Traces?**

Sample traces (e.g., 10%):
```python
import random
if random.random() < 0.1:  # 10% sampling
    os.environ["LANGCHAIN_TRACING_V2"] = "true"
```

## ðŸ“š Resources

- **LangSmith Docs**: https://docs.smith.langchain.com/
- **LangSmith Cookbook**: https://github.com/langchain-ai/langsmith-cookbook
- **YouTube Tutorials**: Search "LangSmith tutorial"
- **Discord**: LangChain Discord server

## ðŸ’¡ Pro Tips

1. **Use Projects** - Separate dev/staging/prod
2. **Tag Everything** - Makes filtering easier
3. **Create Dashboards** - Custom views for metrics
4. **Export Data** - Download traces for analysis
5. **Share Traces** - Collaborate with team

## ðŸŽ‰ Benefits You'll Get

âœ… **Instant Debugging** - See exactly what went wrong
âœ… **Performance Insights** - Identify bottlenecks
âœ… **Cost Optimization** - Track and reduce API costs
âœ… **Quality Improvement** - Test and compare approaches
âœ… **User Analytics** - Understand usage patterns

---

**Start using LangSmith today to take your RAG system to the next level!** ðŸš€
